<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>分类: python爬虫 - WebDog</title><meta property="og:type" content="blog"><meta property="og:title" content="WebDog"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="WebDog"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="WebDog"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"WebDog","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"WebDog"},"description":""}</script><link rel="alternative" href="/atom.xml" title="WebDog" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="WebDog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/webysx"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">分类</a></li><li class="is-active"><a href="#" aria-current="page">python爬虫</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-02-11T13:19:02.000Z" title="2020-02-11T13:19:02.000Z">2020-02-11</time><span class="level-item"><a class="link-muted" href="/categories/python%E7%88%AC%E8%99%AB/">python爬虫</a></span><span class="level-item">12 分钟 读完 (大约 1857 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/">python爬虫实践</a></h1><div class="content"><h1 id="1-中国大学排名-定向爬取"><a href="#1-中国大学排名-定向爬取" class="headerlink" title="1.中国大学排名(定向爬取)"></a>1.中国大学排名(定向爬取)</h1><p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/1.png" alt="1"></p>
<p><strong>爬取路线：</strong>requests+bs4；</p>
<p><strong>定向爬虫：</strong>仅对某一特定的页面进行爬取，不扩展爬取；</p>
<p><strong>可行性：</strong> <a href="http://www.zuihaodaxue.com/robots.txt；">http://www.zuihaodaxue.com/robots.txt；</a></p>
<p><strong>实现结果：</strong></p>
<p><strong>页面结构：</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;tbody class="hidden_zhpm" style="text-align: center;"&gt;</span><br><span class="line">	&lt;tr class="alt"&gt;</span><br><span class="line">		&lt;td&gt;1&lt;/td&gt;</span><br><span class="line">		&lt;td&gt;	</span><br><span class="line">			&lt;div align="left"&gt;清华大学&lt;/div&gt;</span><br><span class="line">		&lt;/td&gt;</span><br><span class="line">		&lt;td&gt;北京&lt;/td&gt;</span><br><span class="line">		&lt;td&gt;95.3&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator5"&gt;100.0&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator6" style="display: none;"&gt;97.50%&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator7" style="display: none;"&gt;1182145&lt;/td&gt;</span><br><span class="line">            &lt;td class="hidden-xs need-hidden indicator8" style="display: none;"&gt;44730&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator9" style="display: none;"&gt;1.447&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator10" style="display: none;"&gt;1556&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator11" style="display: none;"&gt;121&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator12" style="display: none;"&gt;1586283&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator13" style="display: none;"&gt;500525&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator14" style="display: none;"&gt;6.90%&lt;/td&gt;</span><br><span class="line">	&lt;/tr&gt;</span><br></pre></td></tr></table></figure>

<p><strong>思路：</strong></p>
<ol>
<li>从网页上获取页面内容;</li>
<li>提取需要的数据；</li>
<li>输出结果。</li>
</ol>
<p><strong>代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取页面内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,timeout = <span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提取关键信息,将html页面存放在ulist列表中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">university_list</span><span class="params">(ulist,text)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(text,<span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>,class_ = <span class="string">"hidden_zhpm"</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr,bs4.element.Tag):<span class="comment">#isinstance函数检查tr中的内容是否是标签类型，过滤字符串类型</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>)</span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string,tds[<span class="number">1</span>].string,tds[<span class="number">2</span>].string,tds[<span class="number">3</span>].string,tds[<span class="number">4</span>].string])</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出结果,num表示打印的学校数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_university_list</span><span class="params">(ulist,num)</span>:</span></span><br><span class="line">    list_width=<span class="string">"&#123;0:&#123;5&#125;^6&#125;\t&#123;1:&#123;5&#125;^10&#125;\t&#123;2:&#123;5&#125;^6&#125;\t&#123;3:&#123;5&#125;^6&#125;\t&#123;4:&#123;5&#125;^6&#125;"</span></span><br><span class="line">    <span class="comment">#&#123;5&#125;表示采用chr(12288)格式进行填充</span></span><br><span class="line">    print(list_width.format(<span class="string">"排名"</span>,<span class="string">"学校名称"</span>,<span class="string">"省市"</span>,<span class="string">"总分"</span>,<span class="string">"生源质量"</span>,chr(<span class="number">12288</span>)))<span class="comment">#打印表头</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):<span class="comment">#利用循环打印列表</span></span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(list_width.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>],u[<span class="number">3</span>],u[<span class="number">4</span>],chr(<span class="number">12288</span>)))</span><br><span class="line">        </span><br><span class="line">university_info=[]</span><br><span class="line">url = <span class="string">'http://www.zuihaodaxue.com/zuihaodaxuepaiming2018.html'</span></span><br><span class="line">html = getHTMLText(url)</span><br><span class="line">university_list(university_info,html)</span><br><span class="line">input_university_list(university_info,<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/2.png" alt="1"></p>
<p><strong>format说明：</strong></p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.jpg" alt="3"></p>
<p>format方法最主要的两个属性是填充和宽度。当从网页上爬取的文本的宽度大于或小于format设定的宽度时，format就会自动按其内定的格式进行填补，默认情况下采用英文的空格。但如果在处理汉字的时候就会遇到问题，因为汉字和英文空格的宽度不同，所以会遇到不对齐的情况。这里的解决方法就是使用<code>chr(12288)</code>的格式来进行填充。</p>
<h1 id="2-爬取静态网站图片（re）"><a href="#2-爬取静态网站图片（re）" class="headerlink" title="2.爬取静态网站图片（re）"></a>2.爬取静态网站图片（re）</h1><p>request + re + time + os </p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import time</span><br><span class="line">import os</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">'''</span><br><span class="line">获取页面</span><br><span class="line">'''</span><br><span class="line">header = &#123;<span class="emphasis">'user-agent'</span>:</span><br><span class="line"><span class="code"> 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'&#125;</span></span><br><span class="line">url = "https://www.nange.cn/gallery/dreams"</span><br><span class="line">r = requests.get(url, headers = header)</span><br><span class="line">html = r.text</span><br><span class="line"></span><br><span class="line">'''</span><br><span class="line">解析页面</span><br><span class="line">'''</span><br><span class="line">urls = re.findall(<span class="emphasis">'&lt;a class=".*?" href="(.*?)" target=".*?" &gt;&lt;/a&gt;'</span>, html)</span><br><span class="line">dir<span class="emphasis">_name = re.findall('&lt;h1&gt;(.*?)&lt;/h1&gt;', html)[-1]</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">'''</span></span><br><span class="line"><span class="emphasis">创建目录，下载照片</span></span><br><span class="line"><span class="emphasis">'''</span></span><br><span class="line"><span class="emphasis">if not os.path.exists(dir_</span>name):</span><br><span class="line"><span class="code">    os.mkdir(dir_name)</span></span><br><span class="line"></span><br><span class="line">for url in urls:</span><br><span class="line"><span class="code">    time.sleep(1)</span></span><br><span class="line"><span class="code">    response = requests.get(url, headers = header)</span></span><br><span class="line"><span class="code">    file_name = url.split('/')[-1]</span></span><br><span class="line"><span class="code">    with open(dir_name + '\\' + file_name, 'wb') as f:</span></span><br><span class="line"><span class="code">        f.write(response.content)</span></span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/4.png" alt="4"></p>
<h1 id="3-爬取静态网站图片（Xpath）"><a href="#3-爬取静态网站图片（Xpath）" class="headerlink" title="3.爬取静态网站图片（Xpath）"></a>3.爬取静态网站图片（Xpath）</h1><p>request + parsel（Xpath） + time + os </p>
<figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> parsel</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"></span><br><span class="line">header = &#123;<span class="string">'user-agent'</span>:</span><br><span class="line"> <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">"https://blog.ccswust.org/14569.html"</span></span><br><span class="line">r = requests.get(url, headers = header)</span><br><span class="line">html = r.<span class="keyword">text</span></span><br><span class="line"><span class="keyword">data</span> = parsel.Selector(html)</span><br><span class="line"></span><br><span class="line">dir_name = <span class="string">'./爬虫代码/3'</span> + <span class="string">'/'</span> + <span class="keyword">data</span>.xpath(<span class="string">'//h1[@class="article-title"]/text()'</span>).extract()[-<span class="number">1</span>]</span><br><span class="line">urls = <span class="keyword">data</span>.xpath(<span class="string">'//p/img/@src'</span>).extract()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">not</span> os.<span class="built_in">path</span>.exists(dir_name):</span><br><span class="line">    os.mkdir(dir_name)</span><br><span class="line"><span class="keyword">for</span> url <span class="built_in">in</span> urls:</span><br><span class="line">    <span class="built_in">time</span>.sleep(<span class="number">1</span>)</span><br><span class="line">    r = requests.get(url, headers = header)</span><br><span class="line">    file_name = url.split(<span class="string">'?'</span>)[<span class="number">0</span>].split(<span class="string">'/'</span>)</span><br><span class="line">    file_name = file_name[-<span class="number">3</span>] + file_name[-<span class="number">2</span>] + file_name[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">with</span> open(dir_name + <span class="string">'/'</span> + file_name, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/5.png" alt="5"></p>
<h1 id="3-猫眼电影Top100（mongo数据库）"><a href="#3-猫眼电影Top100（mongo数据库）" class="headerlink" title="3.猫眼电影Top100（mongo数据库）"></a>3.猫眼电影Top100（mongo数据库）</h1><p>requests + xpath + mongo数据库</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import parsel</span><br><span class="line">import pymongo</span><br><span class="line">import time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Maoyan</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, url, headers)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.url = url</span><br><span class="line">        <span class="keyword">self</span>.headers = headers</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 请求页面</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_html</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        r = requests.get(<span class="keyword">self</span>.url, headers=<span class="keyword">self</span>.headers)</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">self</span>.html = r.text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析页面（Xpath）,返回字典</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        data = parsel.Selector(<span class="keyword">self</span>.html)</span><br><span class="line">        <span class="keyword">self</span>.names = data.xpath(<span class="string">'//p[@class="name"]/a/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">self</span>.stars = data.xpath(<span class="string">'//p[@class="star"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">self</span>.releasetimes = data.xpath(<span class="string">'//p[@class="releasetime"]/text()'</span>).extract()</span><br><span class="line">        score1 = data.xpath(<span class="string">'//p[@class="score"]/i[@class="integer"]/text()'</span>).extract()</span><br><span class="line">        score2 = data.xpath(<span class="string">'//p[@class="score"]/i[@class="fraction"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">self</span>.scores = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.scores.append(score1[i] + score2[i])</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.9'</span>,</span><br><span class="line">    <span class="string">'Cache-Control'</span>: <span class="string">'max-age=0'</span>,</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">    <span class="string">'Cookie'</span>: <span class="string">'_lxsdk_s=1714d9e4259-ff7-dcf-a5e%7C%7C1'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'maoyan.com'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-Dest'</span>: <span class="string">'document'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-Mode'</span>: <span class="string">'navigate'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-Site'</span>: <span class="string">'cross-site'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-User'</span>: <span class="string">'?1'</span>,</span><br><span class="line">    <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mongo_connect = <span class="string">'mongodb://localhost:27017'</span> <span class="comment">#数据库连接</span></span><br><span class="line">mongo_db_name = <span class="string">'maoying_movies'</span> <span class="comment">#数据库名</span></span><br><span class="line">mongo_collection_name = <span class="string">'movies'</span> <span class="comment">#表名</span></span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(mongo_connect) <span class="comment">#创建连接（继承MongoClient类）</span></span><br><span class="line">db = client[mongo_db_name] <span class="comment">#创建数据库</span></span><br><span class="line">collection = db[mongo_collection_name] <span class="comment">#创建表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取top100</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    url = <span class="string">"https://maoyan.com/board/4?offset="</span> + str(i * <span class="number">10</span>) <span class="comment">#翻页规则</span></span><br><span class="line">    data = Maoyan(url, headers)</span><br><span class="line">    data.get_html()</span><br><span class="line">    data.get_data()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">        print(data.names[i].strip() + data.stars[i].strip() + data.releasetimes[i].strip() + data.scores[i].strip())</span><br><span class="line">	<span class="comment">#存入数据库</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">        movie = &#123;</span><br><span class="line">            <span class="string">'name'</span>: data.names[i].strip(),</span><br><span class="line">            <span class="string">'start'</span>: data.stars[i].strip(),</span><br><span class="line">            <span class="string">'releasetime'</span>: data.releasetimes[i].strip(),</span><br><span class="line">            <span class="string">'score'</span>: data.scores[i].strip()</span><br><span class="line">        &#125;</span><br><span class="line">        collection.update_one(&#123;<span class="string">'name'</span>: movie[<span class="string">'name'</span>]&#125;, &#123;<span class="string">'$set'</span>: movie&#125;, upsert=True)</span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        使用update_one来更新或插入数据，第一个&#123;&#125;表示查询条件，第二个&#123;&#125;利用$set操作符插入数据，upsert表示更新或插入，那么存在则更新，不存在则插入（创建）</span></span><br><span class="line"><span class="string">'</span><span class="string">''</span></span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/6.png" alt="6"></p>
<h1 id="4-拉勾网"><a href="#4-拉勾网" class="headerlink" title="4.拉勾网"></a>4.拉勾网</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"><span class="comment">#import pprint</span></span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取要访问页面的cookie</span></span><br><span class="line">def get_cookies(url):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">        &#125;</span><br><span class="line">    response = requests.<span class="builtin-name">get</span>(url, headers = headers)</span><br><span class="line">    return response.cookies</span><br><span class="line"></span><br><span class="line"><span class="comment">#要访问的页面所需要的表单数据（在浏览器中找），除第一页外，其他页都有sid参数，sid参数从前一个页面获取</span></span><br><span class="line">def get_data(first, pn, sid):</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'first'</span>: first,</span><br><span class="line">        <span class="string">'pn'</span>: pn,</span><br><span class="line">        <span class="string">'kd'</span>: <span class="string">'python'</span>,</span><br><span class="line">        <span class="string">'sid'</span>: sid</span><br><span class="line">    &#125;</span><br><span class="line">    return data</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Origin'</span>: <span class="string">'https://www.lagou.com'</span>,</span><br><span class="line">    <span class="string">'Referer'</span>: <span class="string">'https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput='</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span><span class="built_in"> page </span><span class="keyword">in</span> range(1,31):</span><br><span class="line">    time.sleep(11)</span><br><span class="line">    <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">    经过分析，访问https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput=无法获取数据，</span></span><br><span class="line"><span class="string">    需要在xhr中找到对应的数据页面然后通过规定的方法（post）发送请求，其中cookie可在链接过来的页面的到（referer）</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    url = <span class="string">"https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false"</span></span><br><span class="line">    cookies = get_cookies(<span class="string">'https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput='</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span><span class="built_in"> page </span>== 1:</span><br><span class="line">        first = <span class="literal">True</span></span><br><span class="line">        sid = <span class="string">''</span></span><br><span class="line">        data = get_data(first, page, sid)    </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        first = <span class="literal">False</span></span><br><span class="line">        data = get_data(first, page, sid)</span><br><span class="line">    </span><br><span class="line">    response = requests.post(url, headers = headers, <span class="attribute">data</span>=data, cookies = cookies)</span><br><span class="line">    data_response = response.json()</span><br><span class="line">    sid = data_response[<span class="string">'content'</span>][<span class="string">'showId'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">    信息提取</span></span><br><span class="line"><span class="string">    '</span>city<span class="string">': 城市</span></span><br><span class="line"><span class="string">    '</span>companyFullName<span class="string">': 公司名</span></span><br><span class="line"><span class="string">    '</span>companySize<span class="string">': 公司规模</span></span><br><span class="line"><span class="string">    '</span>education<span class="string">': 学历</span></span><br><span class="line"><span class="string">    '</span>positionName<span class="string">': 职位名称</span></span><br><span class="line"><span class="string">    '</span>salary<span class="string">': 薪资</span></span><br><span class="line"><span class="string">    '</span>workYear<span class="string">': 工作时间</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    results = data_response[<span class="string">'content'</span>][<span class="string">'positionResult'</span>][<span class="string">'result'</span>]</span><br><span class="line">    with open(<span class="string">'拉勾职位信息.csv'</span>, <span class="attribute">mode</span>=<span class="string">'a'</span>, <span class="attribute">encoding</span>=<span class="string">'utf-8'</span>) as f:</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> results:</span><br><span class="line">            d = &#123;</span><br><span class="line">                <span class="string">'city'</span> : r[<span class="string">'city'</span>],</span><br><span class="line">                <span class="string">'companyFullName'</span> : r[<span class="string">'companyFullName'</span>],</span><br><span class="line">                <span class="string">'companySize'</span> : r[<span class="string">'companySize'</span>],</span><br><span class="line">                <span class="string">'education'</span> : r[<span class="string">'education'</span>],</span><br><span class="line">                <span class="string">'positionName'</span> : r[<span class="string">'positionName'</span>],</span><br><span class="line">                <span class="string">'salary'</span> : r[<span class="string">'salary'</span>],</span><br><span class="line">                <span class="string">'workYear'</span> : r[<span class="string">'workYear'</span>]</span><br><span class="line">            &#125;</span><br><span class="line">            values = d.values()</span><br><span class="line">            f.write(<span class="string">","</span>.join(values))</span><br><span class="line">            f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.png" alt="5"></p>
<h1 id="5-爬取快代理构建ip池"><a href="#5-爬取快代理构建ip池" class="headerlink" title="5.爬取快代理构建ip池"></a>5.爬取快代理构建ip池</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import parsel</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def check_proxy(proxy_list):</span><br><span class="line">    # 检查ip质量</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    can_use = []</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> proxy </span><span class="keyword">in</span> proxy_list:</span><br><span class="line">        try:</span><br><span class="line">            response = requests.<span class="builtin-name">get</span>(<span class="string">'https://www.baidu.com/'</span>, headers = headers, proxies = proxy, timeout = 0.1)</span><br><span class="line">            <span class="keyword">if</span> response.status_code == 200:</span><br><span class="line">                can_use.append(proxy)</span><br><span class="line">        except Exception as e:</span><br><span class="line">            <span class="builtin-name">print</span>(e)</span><br><span class="line">    return can_use</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line">proxy_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span><span class="built_in"> page </span><span class="keyword">in</span> range(1,11):</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">"====================正在爬取第&#123;&#125;页==================="</span>.format(page))</span><br><span class="line"></span><br><span class="line">    url = <span class="string">'https://www.kuaidaili.com/free/inha/&#123;&#125;/'</span>.format(page)</span><br><span class="line">    r = requests.<span class="builtin-name">get</span>(url, headers = headers)</span><br><span class="line">    # ip，端口，协议类型</span><br><span class="line">    data = parsel.Selector(r.text)</span><br><span class="line">    proxies = data.xpath(<span class="string">'//table[@class="table table-bordered table-striped"]/tbody/tr'</span>)</span><br><span class="line"></span><br><span class="line">    # 代理ip的形式：&#123;<span class="string">'协议类型'</span>：<span class="string">'ip: 端口'</span>&#125;</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> proxy </span><span class="keyword">in</span> proxies:</span><br><span class="line">        proxy_dict = &#123;&#125;</span><br><span class="line">       <span class="built_in"> ip </span>= proxy.xpath(<span class="string">'./td[@data-title="IP"]/text()'</span>).extract()</span><br><span class="line">       <span class="built_in"> port </span>= proxy.xpath(<span class="string">'./td[@data-title="PORT"]/text()'</span>).extract()</span><br><span class="line">        pro_style = proxy.xpath(<span class="string">'./td[@data-title="类型"]/text()'</span>).extract()</span><br><span class="line">        proxy_dict[<span class="string">'pro_style'</span>] = str(ip) + <span class="string">': '</span> + str(port)</span><br><span class="line">        proxy_list.append(proxy_dict)</span><br><span class="line">        <span class="builtin-name">print</span>(proxy_dict)</span><br><span class="line"></span><br><span class="line">    time.sleep(1)</span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">"===================第&#123;&#125;页爬取结束====================="</span>.format(page))</span><br><span class="line"></span><br><span class="line">can_use = check_proxy(proxy_list)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'能用的代理ip：'</span>, can_use)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'能用的代理ip数量：'</span>, len(can_use))</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-02-11T13:17:59.000Z" title="2020-02-11T13:17:59.000Z">2020-02-11</time><span class="level-item"><a class="link-muted" href="/categories/python%E7%88%AC%E8%99%AB/">python爬虫</a></span><span class="level-item">26 分钟 读完 (大约 3958 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/">python爬虫基础</a></h1><div class="content"><h1 id="Requests库"><a href="#Requests库" class="headerlink" title="Requests库"></a>Requests库</h1><h3 id="一、requests库常用方法"><a href="#一、requests库常用方法" class="headerlink" title="一、requests库常用方法"></a>一、requests库常用方法</h3><blockquote>
<p>requests库的主要方法都是由request方法封装而成的。</p>
</blockquote>
<h4 id="1-get方法"><a href="#1-get方法" class="headerlink" title="1.get方法"></a>1.get方法</h4><blockquote>
<p>get方法构造一个向服务器请求资源的Request对象，并返回一个包含服务器资源的Response对象。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(url,**kwargs)</span><br><span class="line"><span class="comment">#url：获取页面的URL链接</span></span><br><span class="line"><span class="comment">#params：字典或字节序列，作为参数增加到url中</span></span><br><span class="line"><span class="comment">#**kwargs：控制访问的参数,可选</span></span><br></pre></td></tr></table></figure>

<p><strong>Response对象属性：</strong></p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">r</span><span class="selector-class">.status_code</span> <span class="selector-id">#http</span>请求的返回状态，200表示成功，其他表示失败</span><br><span class="line"><span class="selector-tag">r</span><span class="selector-class">.text</span> <span class="selector-id">#http</span>响应的页面内容</span><br><span class="line"><span class="selector-tag">r</span><span class="selector-class">.encoding</span> #从<span class="selector-tag">http</span>请求头的<span class="selector-tag">charset</span>字段中猜测出响应内容的编码方式，默认为<span class="selector-tag">ISO-8859-1</span></span><br><span class="line"><span class="selector-tag">r</span><span class="selector-class">.apparent_encoding</span> #从网页内容中分析出响应内容的编码方式</span><br><span class="line"><span class="selector-tag">r</span><span class="selector-class">.content</span> <span class="selector-id">#http</span>响应内容的二进制形式（还原二进制内容，如图片）</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#r</span><span class="selector-class">.apparent_encoding</span>比<span class="selector-tag">r</span><span class="selector-class">.encoding</span>更准确</span><br></pre></td></tr></table></figure>

<h4 id="2-其他常用方法"><a href="#2-其他常用方法" class="headerlink" title="2.其他常用方法"></a>2.其他常用方法</h4><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">requests.request() <span class="comment">#构造一个请求，支撑其他方法</span></span><br><span class="line">requests.head() <span class="comment">#获取HTML网页头信息的方法，对应于HTTP的HEAD</span></span><br><span class="line">requests.<span class="built_in">post</span>() <span class="comment">#向HTML页面提交POST请求，请求向url位置的资源后附加新的数据，对应于HTTP的POST</span></span><br><span class="line">requests.<span class="built_in">put</span>() <span class="comment">#向HTML页面提交PUT请求，请求更新原有的全部资源，对应于HTTP的PUT</span></span><br><span class="line">requests.patch() <span class="comment">#向HTML页面提交局部修改请求，请求更新原有的局部资源对应于HTTP，的PATCH</span></span><br><span class="line">requests.<span class="built_in">delete</span>() <span class="comment">#向HTML页面提交删除请求，请求删除url位置存储的资源，对应于HTTP的DELETE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#相比较put方法，patch方法可以节省网络带宽</span></span><br></pre></td></tr></table></figure>

<h4 id="3-控制访问的参数：（重点1-2-3-4）"><a href="#3-控制访问的参数：（重点1-2-3-4）" class="headerlink" title="3.控制访问的参数：（重点1,2,3,4）"></a>3.控制访问的参数：（重点1,2,3,4）</h4><ol>
<li><p><code>params</code>：字典或字节序列，作为参数增加到url中；</p>
<p>例：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>,<span class="string">'key2'</span>:<span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">'https://www.baidu.com'</span>,params=kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.url)</span><br><span class="line">https://www.baidu.com/?key1=value1&amp;key2=value2</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>data</code>：字典字节序列或文件对象，作为request的内容；</p>
<p>例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>,<span class="string">'key2'</span>:<span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">'https://www.baidu.com'</span>,data=kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>body = <span class="string">'text'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">'https://www.baidu.com'</span>,data=body)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>json</code>：JSON格式的数据，作为request的内容；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>,<span class="string">'key2'</span>:<span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">'https://www.baidu.com'</span>,json=kv)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>headers</code>：字典，http定制头；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hd=&#123;<span class="string">'user-agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">'www.baidu.com'</span>,headers=hd)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>cookies</code>：字典或CookieJar，request中的cookies；</p>
</li>
<li><p><code>auth</code>：元组，支持http认证功能；</p>
</li>
<li><p><code>files</code>：字典类型，传输文件；</p>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fs = &#123;<span class="string">'file'</span>:open(<span class="string">'data.xls'</span>,<span class="string">'rb'</span>)&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">'https://www.baidu.com'</span>,files=fs)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>timeout</code>：设置超时时间，以秒为单位；</p>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">'http://www.baidu.com'</span>,timeout=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>proxies</code>：字典类型，设定代理服务器，可以增加登录认证；</p>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pxs = &#123;<span class="string">'http'</span>:<span class="string">'http://user:pass@10.10.10.1:1234'</span></span><br><span class="line">			<span class="string">'https'</span>:<span class="string">'https://10.10.10.1:4321'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">'https://www.baidu.com'</span>,proxies=pxs)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>allow_redirects</code>：True/False，默认为True，重定向开关；</p>
</li>
<li><p><code>stream</code>：True/False，默认为True，获取内容立即下载开关；</p>
</li>
<li><p><code>verify</code>：True/False，默认为True，认证SSL证书开关；</p>
</li>
<li><p><code>cert</code>：本地SSL证书路径。</p>
</li>
</ol>
<h3 id="二、requests库的常见异常及异常处理"><a href="#二、requests库的常见异常及异常处理" class="headerlink" title="二、requests库的常见异常及异常处理"></a>二、requests库的常见异常及异常处理</h3><p><strong>常见异常：</strong></p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">requests</span><span class="selector-class">.ConnectionError</span> #网络连接错误异常，如<span class="selector-tag">DNS</span>查询失败、服务器防火墙拒绝连接</span><br><span class="line"><span class="selector-tag">requests</span><span class="selector-class">.HTTPError</span> <span class="selector-id">#HTTP</span>错误异常</span><br><span class="line"><span class="selector-tag">requests</span><span class="selector-class">.URLRequired</span> <span class="selector-id">#url</span>缺失异常</span><br><span class="line"><span class="selector-tag">requests</span><span class="selector-class">.TooManyRedirects</span> #超过最大重定向次数，产生重定向异常</span><br><span class="line"><span class="selector-tag">requests</span><span class="selector-class">.ConnectTimeout</span> #连接远程服务器超时异常（与远程服务器连接的过程）</span><br><span class="line"><span class="selector-tag">requests</span><span class="selector-class">.Timeout</span> #请求<span class="selector-tag">url</span>超时，产生超时异常（发出请求到获取内容的整过过程）</span><br></pre></td></tr></table></figure>

<p><strong>异常处理的方法：</strong></p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r.raise_for_status() #判断状态码是否为<span class="number">200</span>，如果不是<span class="number">200</span>，产生异常requests.HTTPError</span><br></pre></td></tr></table></figure>

<h3 id="三、爬取网页的通用代码框架"><a href="#三、爬取网页的通用代码框架" class="headerlink" title="三、爬取网页的通用代码框架"></a>三、爬取网页的通用代码框架</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    url = <span class="string">"http://www.xxx.com"</span></span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></table></figure>



<h1 id="BeautifulSoup库"><a href="#BeautifulSoup库" class="headerlink" title="BeautifulSoup库"></a>BeautifulSoup库</h1><blockquote>
<p>BeautifulSoup库主要用来对爬取的页面内容进行提取。BeautifulSoup是一个可以代表html的类。</p>
</blockquote>
<h3 id="一、BeautifulSoup库的基本元素"><a href="#一、BeautifulSoup库的基本元素" class="headerlink" title="一、BeautifulSoup库的基本元素"></a>一、BeautifulSoup库的基本元素</h3><h4 id="1-BeautifulSoup库解析器"><a href="#1-BeautifulSoup库解析器" class="headerlink" title="1.BeautifulSoup库解析器"></a>1.BeautifulSoup库解析器</h4><table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>条件</th>
</tr>
</thead>
<tbody><tr>
<td>bs4的html解析器</td>
<td>BeautifulSoup(mk,’html.parser’)</td>
<td>pip install bs4</td>
</tr>
<tr>
<td>lxml的html解析器</td>
<td>BeautifulSoup(mk,’lxml’)</td>
<td>pip install lxml</td>
</tr>
<tr>
<td>lxml的xml解析器</td>
<td>BeautifulSoup(mk,’xml’)</td>
<td>pip install lxml</td>
</tr>
<tr>
<td>html5lib的解析器</td>
<td>BeautifulSoup(mk,’html5lib’)</td>
<td>pip install html5lib</td>
</tr>
</tbody></table>
<h4 id="2-BeautifulSoup类的基本元素"><a href="#2-BeautifulSoup类的基本元素" class="headerlink" title="2.BeautifulSoup类的基本元素"></a>2.BeautifulSoup类的基本元素</h4><p><code>tag</code>：标签，最基本的信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾；</p>
<p><code>name</code>：标签的名字；格式：<code>tag.name</code>；</p>
<p><code>attributes</code>：标签的属性，字典形式；格式：<code>tag.attrs</code>；</p>
<p><code>navigablestring</code>：标签内两个括号尖括起来的内容，&lt;&gt;···&lt;/&gt;，···代表的内容；格式：<code>tag.string</code>；</p>
<p><code>comment</code>：标签内字符串的注释部分；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">r=requests.get(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">rs = r.text</span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line">tags = soup.a</span><br><span class="line">print(tags)</span><br><span class="line">print(tags.name)</span><br><span class="line">print(tags.string)</span><br><span class="line">print(tags.attrs)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;a class="mnav" href="http://news.baidu.com" name="tj_trnews"&gt;新闻&lt;/a&gt;</span><br><span class="line">a</span><br><span class="line">新闻</span><br><span class="line">&#123;<span class="string">'href'</span>: <span class="string">'http://news.baidu.com'</span>, <span class="string">'name'</span>: <span class="string">'tj_trnews'</span>, <span class="string">'class'</span>: [<span class="string">'mnav'</span>]&#125;</span><br></pre></td></tr></table></figure>

<h3 id="二、基于bs4库的html内容遍历方法"><a href="#二、基于bs4库的html内容遍历方法" class="headerlink" title="二、基于bs4库的html内容遍历方法"></a>二、基于bs4库的html内容遍历方法</h3><blockquote>
<p>遍历html文档的方法：下行遍历，上行遍历，平行遍历。</p>
</blockquote>
<h4 id="1-下行遍历"><a href="#1-下行遍历" class="headerlink" title="1.下行遍历"></a>1.下行遍历</h4><p><strong>下行遍历的属性：</strong></p>
<p><code>.contents</code>：子节点的列表，将tag所有的儿子节点存入列表；</p>
<p><code>.children</code>：子节点的迭代类型，与<code>.contents</code>类似，用于循环遍历儿子节点；</p>
<p><code>.descendants</code>：子孙节点的迭代类型，包含所有子孙节点，用于循环遍历。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www,baidu.com"</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">rs = r.text</span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#遍历子节点</span></span><br><span class="line">print(soup.head.contents)</span><br><span class="line"></span><br><span class="line"><span class="comment">#遍历儿子节点</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.head.children:</span><br><span class="line">    print(child)</span><br><span class="line"><span class="comment">#children是一个迭代器</span></span><br><span class="line">print(soup.head.children)</span><br><span class="line"></span><br><span class="line"><span class="comment">#遍历所有子孙节点</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.head.descendants:</span><br><span class="line">    print(child)</span><br><span class="line">    print(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[&lt;meta content="text/html;charset=utf-8" http-equiv="content-type"/&gt;, &lt;meta content="IE=Edge" http-equiv="X-UA-Compatible"/&gt;, &lt;meta content="always" name="referrer"/&gt;, &lt;link href="https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css" rel="stylesheet" type="text/css"/&gt;, &lt;title&gt;百度一下，你就知道&lt;/title&gt;]</span><br><span class="line"></span><br><span class="line">&lt;meta content=<span class="string">"text/html;charset=utf-8"</span> http-equiv=<span class="string">"content-type"</span>/&gt;</span><br><span class="line">&lt;meta content=<span class="string">"IE=Edge"</span> http-equiv=<span class="string">"X-UA-Compatible"</span>/&gt;</span><br><span class="line">&lt;meta content=<span class="string">"always"</span> name=<span class="string">"referrer"</span>/&gt;</span><br><span class="line">&lt;link href=<span class="string">"https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css"</span> rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span>/&gt;</span><br><span class="line">&lt;title&gt;百度一下，你就知道&lt;/title&gt;</span><br><span class="line"></span><br><span class="line">&lt;list_iterator object at <span class="number">0x000001BAE9F7D8C8</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;meta content=<span class="string">"IE=Edge"</span> http-equiv=<span class="string">"X-UA-Compatible"</span>/&gt;</span><br><span class="line">&lt;div id="wrapper"&gt; &lt;div id="head"&gt; &lt;div class="head_wrapper"&gt; &lt;div class="s_form"&gt; &lt;div class="s_form_wrapper"&gt; &lt;div id="lg"&gt; &lt;img height="129" hidefocus="true" src="//www.baidu.com/img/bd_logo1.png" width="270"/&gt; &lt;/div&gt; &lt;form action="//www.baidu.com/s" class="fm" id="form" name="f"&gt; &lt;input name="bdorz_come" type="hidden" value="1"/&gt;···</span><br><span class="line"></span><br><span class="line">                &lt;/script&gt; &lt;a class="bri" href="//www.baidu.com/more/" name="tj_briicon" style="display: block;"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="ftCon"&gt; &lt;div id="ftConw"&gt; &lt;p id="lh"&gt; &lt;a href="http://home.baidu.com"&gt;关于百度&lt;/a&gt; &lt;a href="http://ir.baidu.com"&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id="cp"&gt;©2017 Baidu &lt;a href="http://www.baidu.com/duty/"&gt;使用百度前必读&lt;/a&gt;  &lt;a class="cp-feedback" href="http://jianyi.baidu.com/"&gt;意见反馈&lt;/a&gt; 京ICP证030173号  &lt;img src="//www.baidu.com/img/gs.gif"/&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;div id="head"&gt; &lt;div class="head_wrapper"&gt; &lt;div class="s_form"&gt; &lt;div class="s_form_wrapper"&gt; ···</span><br><span class="line"></span><br><span class="line">                &lt;/script&gt; &lt;a class="bri" href="//www.baidu.com/more/" name="tj_briicon" style="display: block;"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;div class="head_wrapper"&gt; &lt;div class="s_form"&gt; &lt;div class="s_form_wrapper"&gt; &lt;div id="lg"&gt; &lt;img height="129" hidefocus="true" src="//www.baidu.com/img/bd_logo1.png" width="270"/&gt; &lt;/div&gt; ···</span><br><span class="line"></span><br><span class="line">                &lt;/script&gt; &lt;a class="bri" href="//www.baidu.com/more/" name="tj_briicon" style="display: block;"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;div class="s_form"&gt; &lt;div class="s_form_wrapper"&gt; &lt;div id="lg"&gt; &lt;img height="129" hidefocus="true" src="//www.baidu.com/img/bd_logo1.png" width="270"/&gt; &lt;/div&gt; &lt;form action="//www.baidu.com/s" class="fm" id="form" name="f"&gt; &lt;input name="bdorz_come" type="hidden" value="1"/&gt; ···</span><br><span class="line"></span><br><span class="line">&lt;div class="s_form_wrapper"&gt; &lt;div id="lg"&gt; &lt;img height="129" hidefocus="true" src="//www.baidu.com/img/bd_logo1.png" width="270"/&gt; &lt;/div&gt; &lt;form action="//www.baidu.com/s" class="fm" id="form" name="f"&gt; &lt;input name="bdorz_come" type="hidden" value="1"/&gt; &lt;input····</span><br><span class="line"></span><br><span class="line">&lt;div id="lg"&gt; &lt;img height="129" hidefocus="true" src="//www.baidu.com/img/bd_logo1.png" width="270"/&gt; &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;img height=<span class="string">"129"</span> hidefocus=<span class="string">"true"</span> src=<span class="string">"//www.baidu.com/img/bd_logo1.png"</span> width=<span class="string">"270"</span>/&gt;</span><br><span class="line"></span><br><span class="line">&lt;form action="//www.baidu.com/s" class="fm" id="form" name="f"&gt; &lt;input name="bdorz_come" type="hidden" value="1"/&gt; &lt;···</span><br><span class="line"></span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">···</span><br></pre></td></tr></table></figure>

<h4 id="2-上行遍历"><a href="#2-上行遍历" class="headerlink" title="2.上行遍历"></a>2.上行遍历</h4><p><strong>上行遍历的属性：</strong></p>
<p><code>.parent</code>：节点的父亲标签；</p>
<p><code>.parents</code>：节点先辈标签的迭代类型，用于循环遍历先辈节点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.baidu.com"</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">rs = r.text</span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line">print(soup.title.parent)</span><br><span class="line"><span class="comment">#标签树的上行遍历</span></span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.head.parents:</span><br><span class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        print(parent)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(parent.name)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;head&gt;&lt;meta content="text/html;charset=utf-8" http-equiv="content-type"/&gt;&lt;meta content="IE=Edge" http-equiv="X-UA-Compatible"/&gt;&lt;meta content="always" name="referrer"/&gt;&lt;link href="https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css" rel="stylesheet" type="text/css"/&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">html</span><br><span class="line">[document]</span><br><span class="line"><span class="comment">#遍历所有先辈标签时，会遍历soup标签本身，但soup的先辈标签没有.name属性</span></span><br></pre></td></tr></table></figure>

<h4 id="3-平行遍历"><a href="#3-平行遍历" class="headerlink" title="3.平行遍历"></a>3.平行遍历</h4><blockquote>
<p>平行遍历发生在同一个父亲节点下的各节点间。</p>
</blockquote>
<p><strong>平行遍历的属性：</strong></p>
<p><code>.next_sibling</code>：返回按照HTML文本顺序的下一个平行节点标签；</p>
<p><code>.previous_sibling</code>：返回按照HTML文本顺序的下一个平行节点标签；</p>
<p><code>.next_siblings</code>：迭代类型，返回按照HTML文本顺序的后续所有平行节点标签；</p>
<p><code>.previous_siblings</code>：迭代类型，返回按照HTML文本格式的前续所有平行节点标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#遍历后续节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">    print(sibling)</span><br><span class="line"><span class="comment">#遍历前续节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.previous_siblings:</span><br><span class="line">    print(sibling)</span><br></pre></td></tr></table></figure>

<h3 id="三、基于bs4库的html格式化和编码"><a href="#三、基于bs4库的html格式化和编码" class="headerlink" title="三、基于bs4库的html格式化和编码"></a>三、基于bs4库的html格式化和编码</h3><h4 id="1-bs4库的prettify-方法"><a href="#1-bs4库的prettify-方法" class="headerlink" title="1.bs4库的prettify()方法"></a>1.bs4库的prettify()方法</h4><blockquote>
<p>bs4库中的prettify()方法在每一个HTML标签后面加一个换行符，美化格式。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">head = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">"https://www.php.net/manual/zh/index.php"</span></span><br><span class="line">r = requests.get(url,headers = head)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">rs = r.text</span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&lt;head&gt;</span><br><span class="line"> &lt;meta charset=<span class="string">"utf-8"</span>/&gt;</span><br><span class="line"> &lt;meta content=<span class="string">"width=device-width, initial-scale=1.0"</span> name=<span class="string">"viewport"</span>/&gt;</span><br><span class="line"> &lt;title&gt;</span><br><span class="line">  PHP: PHP 手册 - Manual</span><br><span class="line"> &lt;/title&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/favicon.ico"</span> rel=<span class="string">"shortcut icon"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"http://php.net/phpnetimprovedsearch.src"</span> rel=<span class="string">"search"</span> title=<span class="string">"Add PHP.net search"</span> type=<span class="string">"application/opensearchdescription+xml"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/releases/feed.php"</span> rel=<span class="string">"alternate"</span> title=<span class="string">"PHP Release feed"</span> type=<span class="string">"application/atom+xml"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/feed.atom"</span> rel=<span class="string">"alternate"</span> title=<span class="string">"PHP: Hypertext Preprocessor"</span> type=<span class="string">"application/atom+xml"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/index.php"</span> rel=<span class="string">"canonical"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/index.php"</span> rel=<span class="string">"shorturl"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/index.php"</span> hreflang=<span class="string">"x-default"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/index.php"</span> rel=<span class="string">"contents"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/"</span> rel=<span class="string">"index"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/"</span> rel=<span class="string">"prev"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/"</span> rel=<span class="string">"next"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/en/index.php"</span> hreflang=<span class="string">"en"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/pt_BR/index.php"</span> hreflang=<span class="string">"pt_BR"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/zh/index.php"</span> hreflang=<span class="string">"zh"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/fr/index.php"</span> hreflang=<span class="string">"fr"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/de/index.php"</span> hreflang=<span class="string">"de"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/ja/index.php"</span> hreflang=<span class="string">"ja"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/ro/index.php"</span> hreflang=<span class="string">"ro"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/ru/index.php"</span> hreflang=<span class="string">"ru"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/es/index.php"</span> hreflang=<span class="string">"es"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"https://www.php.net/manual/tr/index.php"</span> hreflang=<span class="string">"tr"</span> rel=<span class="string">"alternate"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"/cached.php?t=1539771603&amp;amp;f=/fonts/Fira/fira.css"</span> media=<span class="string">"screen"</span> rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"/cached.php?t=1539765004&amp;amp;f=/fonts/Font-Awesome/css/fontello.css"</span> media=<span class="string">"screen"</span> rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"/cached.php?t=1540425603&amp;amp;f=/styles/theme-base.css"</span> media=<span class="string">"screen"</span> rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span>/&gt;</span><br><span class="line"> &lt;link href=<span class="string">"/cached.php?t=1540425603&amp;amp;f=/styles/theme-medium.css"</span> media=<span class="string">"screen"</span> rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span>/&gt;</span><br><span class="line"> &lt;!--[<span class="keyword">if</span> lte IE <span class="number">7</span>]&gt;</span><br><span class="line"> &lt;link rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span> href=<span class="string">"https://www.php.net/styles/workarounds.ie7.css"</span> media=<span class="string">"screen"</span>&gt;</span><br><span class="line"> &lt;![endif]--&gt;</span><br><span class="line"> &lt;!--[<span class="keyword">if</span> lte IE <span class="number">8</span>]&gt;</span><br><span class="line"> &lt;script&gt;</span><br><span class="line">  window.brokenIE = true;</span><br><span class="line"> &lt;/script&gt;</span><br><span class="line"> &lt;![endif]--&gt;</span><br><span class="line"> &lt;!--[<span class="keyword">if</span> lte IE <span class="number">9</span>]&gt;</span><br><span class="line"> &lt;link rel=<span class="string">"stylesheet"</span> type=<span class="string">"text/css"</span> href=<span class="string">"https://www.php.net/styles/workarounds.ie9.css"</span> media=<span class="string">"screen"</span>&gt;</span><br><span class="line"> &lt;![endif]--&gt;</span><br><span class="line"> &lt;!--[<span class="keyword">if</span> IE]&gt;</span><br><span class="line"> &lt;script src="https://www.php.net/js/ext/html5.js"&gt;&lt;/script&gt;</span><br><span class="line"> &lt;![endif]--&gt;</span><br><span class="line"> &lt;base href=<span class="string">"https://www.php.net/manual/zh/index.php"</span>/&gt;</span><br><span class="line">&lt;/head&gt;</span><br></pre></td></tr></table></figure>

<h3 id="四、信息组织与提取方法"><a href="#四、信息组织与提取方法" class="headerlink" title="四、信息组织与提取方法"></a>四、信息组织与提取方法</h3><h4 id="1-三种信息标记形式"><a href="#1-三种信息标记形式" class="headerlink" title="1.三种信息标记形式"></a>1.三种信息标记形式</h4><p><strong>XML</strong>：用尖括号，标签表达信息的标记形式；Internet上的信息交互与传递；</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;name&gt;...&lt;/name&gt;</span><br><span class="line">&lt;name/&gt;</span><br><span class="line">&lt;!-- --&gt;</span><br></pre></td></tr></table></figure>

<p><strong>JSON</strong>：用有类型的键值对标记信息的表达形式；移动应用云端和节点的信息通信，主要用于接口，无注释；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'key'</span>:<span class="string">'value'</span></span><br><span class="line"><span class="string">'key'</span>:[<span class="string">'value1'</span>,<span class="string">'value2'</span>]</span><br><span class="line"><span class="string">'key'</span>:&#123;<span class="string">'subkey'</span>:<span class="string">'subvalue'</span>&#125;</span><br></pre></td></tr></table></figure>

<p><strong>YAML</strong>：用无类型的键值对标记信息的表达形式；各类系统的配置文件，有注释易读；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">key:value</span><br><span class="line">key:<span class="comment">#Comment</span></span><br><span class="line">-value1</span><br><span class="line">-value2</span><br><span class="line">key:</span><br><span class="line">	subkey:subvalue</span><br></pre></td></tr></table></figure>

<h4 id="2-信息提取的一般方法"><a href="#2-信息提取的一般方法" class="headerlink" title="2.信息提取的一般方法"></a>2.信息提取的一般方法</h4><p><strong>方法一</strong>：完整解析信息的标记形式，再提取关键信息；信息解析准确，但提取过程繁琐，速度慢；</p>
<p><strong>方法二</strong>：无视标记形式，使用查找函数，直接搜索关键信息；提取过程简洁，速度快，但结果缺乏准确性；</p>
<p><strong>融合方法</strong>：方法一 + 方法二。</p>
<p><strong>例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">head = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">"https://www.php.net/manual/zh/index.php"</span></span><br><span class="line">r = requests.get(url,headers = head)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">rs = r.text</span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">'a'</span>):</span><br><span class="line">    print(link.get(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/</span><br><span class="line">/downloads</span><br><span class="line">/docs.php</span><br><span class="line">/get-involved</span><br><span class="line">/support</span><br><span class="line">/index.php<span class="comment">#id2020-02-20-3</span></span><br><span class="line">/manual/en/getting-started.php</span><br><span class="line">/manual/en/introduction.php</span><br><span class="line">/manual/en/tutorial.php</span><br><span class="line">/manual/en/langref.php</span><br><span class="line">/manual/en/language.basic-syntax.php</span><br><span class="line">/manual/en/language.types.php</span><br><span class="line">/manual/en/language.variables.php</span><br><span class="line">/manual/en/language.constants.php</span><br><span class="line">/manual/en/language.expressions.php</span><br><span class="line">/manual/en/language.operators.php</span><br><span class="line">/manual/en/language.control-structures.php</span><br><span class="line">/manual/en/language.functions.php</span><br><span class="line">/manual/en/language.oop5.php</span><br><span class="line">/manual/en/language.namespaces.php</span><br><span class="line">/manual/en/language.errors.php</span><br><span class="line">···</span><br><span class="line">···</span><br></pre></td></tr></table></figure>

<h3 id="五、基于bs4库的HTML内容查找方法"><a href="#五、基于bs4库的HTML内容查找方法" class="headerlink" title="五、基于bs4库的HTML内容查找方法"></a>五、基于bs4库的HTML内容查找方法</h3><p><code>.find_all(name,attrs,recursive,string,**kwarges)</code>：返回一个列表类型，存储查找的结果；</p>
<p><code>name</code>：对标签名称的检索字符串；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">find_all(<span class="string">'a'</span>) <span class="comment">#查找a标签</span></span><br><span class="line">find_all([<span class="string">'a'</span>,<span class="string">'b'</span>]) <span class="comment">#查找a，b标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查找网页代码的所有标签、</span></span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(<span class="literal">True</span>):</span><br><span class="line">    print(tag.name)</span><br><span class="line">返回结果：</span><br><span class="line">html</span><br><span class="line">head</span><br><span class="line">meta</span><br><span class="line">title</span><br><span class="line">link</span><br><span class="line">···</span><br><span class="line">li</span><br><span class="line">a</span><br><span class="line">li</span><br><span class="line">script</span><br><span class="line">a</span><br><span class="line">span</span><br><span class="line">img</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印以字母b开头的标签（re正则）</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">head = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">"https://www.php.net/manual/zh/index.php"</span></span><br><span class="line">r = requests.get(url,headers = head)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">rs = r.text</span><br><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">'b'</span>)):</span><br><span class="line">    print(tag.name)</span><br><span class="line">返回结果：</span><br><span class="line">base</span><br><span class="line">body</span><br><span class="line">br</span><br><span class="line">label</span><br><span class="line">br</span><br></pre></td></tr></table></figure>

<p><code>attrs</code>：对标签属性值的检索字符串，可标注属性检索；</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line">print(soup.find_all(<span class="string">'div'</span>,<span class="string">'copyright'</span>))</span><br><span class="line">运行结果：（返回内容包含©）</span><br><span class="line">[&lt;div class="copyright"&gt;©</span><br><span class="line">   &lt;span class="year"&gt;1997-2020&lt;/span&gt;</span><br><span class="line">&lt;span class="holder"&gt;PHP 文档组&lt;/span&gt;</span><br><span class="line">&lt;/div&gt;]</span><br></pre></td></tr></table></figure>

<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(rs,<span class="string">'html.parser'</span>)</span><br><span class="line">print(soup.find_all(<span class="string">'div'</span>,id = <span class="string">'goto'</span>))</span><br><span class="line">print(soup.find_all(id=<span class="string">'goto'</span>))</span><br><span class="line">运行结果：</span><br><span class="line">[&lt;div id=<span class="string">"goto"</span>&gt;</span><br><span class="line">&lt;div class="search"&gt;</span><br><span class="line">&lt;div class="text"&gt;&lt;/div&gt;</span><br><span class="line">&lt;div class="results"&gt;&lt;ul&gt;&lt;/ul&gt;&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;]</span><br><span class="line">[&lt;div id=<span class="string">"goto"</span>&gt;</span><br><span class="line">&lt;div class="search"&gt;</span><br><span class="line">&lt;div class="text"&gt;&lt;/div&gt;</span><br><span class="line">&lt;div class="results"&gt;&lt;ul&gt;&lt;/ul&gt;&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;]</span><br></pre></td></tr></table></figure>

<p><code>recursive</code>：是否对子孙全部检索，默认是True；recursive=False；</p>
<p><code>string</code>：对&lt;&gt;…&lt;/&gt;中字符区域的检索字符串；string=’info’。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">soup.div.find_all(string = <span class="string">'ihugvfcdxc'</span>)要注意的是string中的内容格式必须跟网页上的内容一致，哦负责结果返回为空</span><br><span class="line">soup.find_all(<span class="string">'a'</span>,string = <span class="string">'tgyhujik'</span>)</span><br><span class="line">soup.find_all(string = <span class="string">'tgyhujik'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/1.jpg" alt="1"></p>
<p><strong>按id或class_查找文本内容：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(id = <span class="string">'link'</span>)</span><br><span class="line">soup.div.find_all(id = <span class="string">'link'</span>)</span><br><span class="line">soup.find_all(<span class="string">'div'</span>,id = <span class="string">'link'</span>)</span><br><span class="line">soup,find_all(class_ = <span class="string">'link'</span>) <span class="comment">#class_加下划线以区别于class</span></span><br><span class="line">soup.div.find_all(id = <span class="string">'link'</span>)</span><br><span class="line">soup.find_all(<span class="string">'div'</span>,class_ = <span class="string">'link'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>获取子孙节点：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>,class_ = <span class="string">"hidden_zhpm"</span>).children:</span><br><span class="line">	print(tr(<span class="string">'td'</span>))</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">'a'</span>):</span><br><span class="line">    print(link.get(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure>

<h3 id="六、输出"><a href="#六、输出" class="headerlink" title="六、输出"></a>六、输出</h3><h4 id="1-格式化输出"><a href="#1-格式化输出" class="headerlink" title="1.格式化输出"></a>1.格式化输出</h4><blockquote>
<p>python一般使用<code>.format</code>方法来进行格式化输出。</p>
</blockquote>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/2.jpg" alt="1"></p>
<p><strong>使用：</strong></p>
<p>1、按照默认顺序，不指定位置</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"&#123;&#125; &#123;&#125;"</span>.format(<span class="string">"hello"</span>,<span class="string">"world"</span>)</span></span> )</span><br><span class="line"></span><br><span class="line">hello world</span><br></pre></td></tr></table></figure>

<p>2、设置指定位置，可以多次使用</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"&#123;0&#125; &#123;1&#125; &#123;0&#125;"</span>.format(<span class="string">"hello"</span>,<span class="string">"or"</span>)</span></span>)</span><br><span class="line"></span><br><span class="line">hello or hello</span><br></pre></td></tr></table></figure>

<p>3、使用字典格式化</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">person = &#123;"name":"opcai","age":<span class="number">20</span>&#125;</span><br><span class="line">print("My name is &#123;name&#125; . I am &#123;age&#125; years old .".format(**person))</span><br><span class="line"></span><br><span class="line">My <span class="type">name</span> <span class="keyword">is</span> opcai . I am <span class="number">20</span> years <span class="built_in">old</span> .</span><br></pre></td></tr></table></figure>

<p>4、通过列表格式化</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stu = ["opcai","linux","MySQL","Python"]</span><br><span class="line">print("My name is &#123;0[0]&#125; , I love &#123;0[1]&#125; !".format(stu))</span><br><span class="line"></span><br><span class="line">My <span class="type">name</span> <span class="keyword">is</span> opcai , I love linux !</span><br></pre></td></tr></table></figure>

<p> ^, &lt;, &gt; 分别是居中、左对齐、右对齐，后面带宽度， : 号后面带填充的字符，只能是一个字符，不指定则默认是用空格填充。 </p>
<p>大括号用大括号转义：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"&#123;&#125; &#123;&#123;0&#125;&#125;"</span>.format(<span class="string">"opcai_linux"</span>)</span></span>)</span><br><span class="line"></span><br><span class="line">opcai_linux &#123;<span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>

<p> <a href="https://baijiahao.baidu.com/s?id=1618722730278133164&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1618722730278133164&amp;wfr=spider&amp;for=pc</a> </p>
<p> <a href="https://www.runoob.com/python/att-string-format.html">https://www.runoob.com/python/att-string-format.html</a> </p>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><h2 id="一、基本语法"><a href="#一、基本语法" class="headerlink" title="一、基本语法"></a>一、基本语法</h2><blockquote>
<p>正则表达式语法由字符和操作符构成。</p>
</blockquote>
<h3 id="1-操作符"><a href="#1-操作符" class="headerlink" title="1.操作符"></a>1.操作符</h3><table>
<thead>
<tr>
<th>操作符</th>
<th>说明</th>
<th>实例</th>
</tr>
</thead>
<tbody><tr>
<td>.</td>
<td>表示任何单个字符</td>
<td></td>
</tr>
<tr>
<td>[ ]</td>
<td>字符集，对单个字符给出取值范围</td>
<td>[abc]，[a-z]</td>
</tr>
<tr>
<td>[^ ]</td>
<td>非字符集，对单个字符给出排除范围</td>
<td>[^abc]</td>
</tr>
<tr>
<td>*</td>
<td>前一个字符0次或无限次重复</td>
<td>abc*表示ab、abc、abcc等</td>
</tr>
<tr>
<td>+</td>
<td>前一个字符1次或无限次重复</td>
<td>abc+</td>
</tr>
<tr>
<td>?</td>
<td>前一个字符0次或1次重复</td>
<td>abc?</td>
</tr>
<tr>
<td>|</td>
<td>表达式左右任意一个</td>
<td>A|B，表示A或B</td>
</tr>
</tbody></table>
<h1 id="Xpath"><a href="#Xpath" class="headerlink" title="Xpath"></a>Xpath</h1><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import parsel</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">'''</span><br><span class="line">parsel能够把缺失的HTML标签补充完整</span><br><span class="line">'''</span><br><span class="line">header = &#123;<span class="emphasis">'user-agent'</span>:</span><br><span class="line"><span class="code"> 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'&#125;</span></span><br><span class="line">url = "https://blog.ccswust.org/14569.html"</span><br><span class="line">r = requests.get(url, headers = header)</span><br><span class="line">data = parsel.Selector(r.text) #转换数据类型，将字符串（str）转换为Selector类</span><br><span class="line">'''</span><br><span class="line">Xpath提取数据，返回的结果是一个列表，如果想要获得标签的具体内容，要使用extract()方法</span><br><span class="line">'''</span><br><span class="line">#data = parsel.Selector(r.text).getall()</span><br><span class="line">#data = parsel.Selector(r.text).extract()</span><br><span class="line"></span><br><span class="line">#从根节点开始获取所有img标签，精确</span><br><span class="line">result1 = data.xpath(<span class="emphasis">'/html/body/section/div/div/article/p/img'</span>).extract()</span><br><span class="line">#跨节点获取所有img标签, 不精确</span><br><span class="line">result2 = data.xpath(<span class="emphasis">'//img'</span>).extract()</span><br><span class="line">#选取当前节点，对当前节点的下一个节点进行提取，获取所有p标签下的img标签</span><br><span class="line">result3 = data.xpath(<span class="emphasis">'//p/img'</span>).extract()</span><br><span class="line">#或者</span><br><span class="line">result3 = data.xpath(<span class="emphasis">'//p'</span>)</span><br><span class="line">result4 = result3.xpath(<span class="emphasis">'./img'</span>).extract()</span><br><span class="line">#选取所有图片的url（即获取img标签的src属性）</span><br><span class="line">result5 = data.xpath(<span class="emphasis">'//p/img/@src'</span>).extract()</span><br><span class="line">#选取当前节点的父节点,输出结果是父节点包含的所有节点</span><br><span class="line">result6 = data.xpath(<span class="emphasis">'//p'</span>)[1] #只选取第二个列表元素</span><br><span class="line">result7 = result6.xpath(<span class="emphasis">'..'</span>).extract()</span><br><span class="line">#len(result7)=1</span><br><span class="line">#获取父节点的class属性值</span><br><span class="line">result8 = data.xpath(<span class="emphasis">'//p'</span>)</span><br><span class="line">result9 = result8.xpath(<span class="emphasis">'../@class'</span>).extract()</span><br><span class="line">#平行节点之间相互获取,xpath索引（从1开始）;获取第三个img标签（两种方法，注意区别）</span><br><span class="line">#1.</span><br><span class="line">result10 = data.xpath(<span class="emphasis">'//p[3]/img'</span>).extract() </span><br><span class="line">'''</span><br><span class="line">这里方法1有点问题，不能直接提取第三个img标签，因为前提是被提取的标签必须要有子节点，</span><br><span class="line">因为img标签没有子节点，所以提取到的结果为空，只能通过p标签间接提取,img标签可以限制p的范围，即所有包含img节点的p节点</span><br><span class="line">'''</span><br><span class="line">#2.(首选)</span><br><span class="line">result11 = data.xpath(<span class="emphasis">'//p/img'</span>)[2].extract()</span><br><span class="line">#通过属性精准定位,获取所有与需爬取图片有关的img标签,并获取所有url</span><br><span class="line">result12 = data.xpath(<span class="emphasis">'//img[@class="img-thumbnail"]/@src'</span>).extract()</span><br><span class="line">#获取标签包含的文本内容,获取标题以作为保存图片的文件夹名</span><br><span class="line">result13 = data.xpath(<span class="emphasis">'//h1[@class="article-title"]/text()'</span>).extract()[1]</span><br><span class="line">'''</span><br><span class="line">要注意的是，xpath提取数据会包含所有节点，不会跳过子节点，h1标签中包含了a标签，上面的代码也会输出a标签的text，</span><br><span class="line">只是a标签没有包含文本，所以返回结果为空</span><br><span class="line">上面代码如果不加[1]，返回结果为[' <span class="emphasis">', '</span>少女情怀总是诗<span class="emphasis">']</span></span><br><span class="line"><span class="emphasis">'</span>'<span class="emphasis">'</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">'</span>'<span class="emphasis">'</span></span><br><span class="line"><span class="emphasis">注意区分“利用属性值定位标签”和“获取标签的属性值”</span></span><br><span class="line"><span class="emphasis">'</span>'<span class="emphasis">'</span></span><br><span class="line"><span class="emphasis">#模糊查询,关键字contains(属性，属性值（模糊）)</span></span><br><span class="line"><span class="emphasis">result13 = data.xpath('</span>//img[contains(@class,"img")]<span class="emphasis">').extract()#class属性值包含“img”内容的img标签</span></span><br><span class="line"><span class="emphasis">#同时选取多个标签，用 | 运算符</span></span><br></pre></td></tr></table></figure>

</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="" src="/img/avatar.png" alt="WebDog"></figure><p class="title is-size-4 is-block line-height-inherit">WebDog</p><p class="is-size-6 is-block">莫得感情的Web渗透测试机器</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ChengDu</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/webysx" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/webysx"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/php%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"><span class="level-start"><span class="level-item">php代码审计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/python%E7%88%AC%E8%99%AB/"><span class="level-start"><span class="level-item">python爬虫</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/sql%E6%B3%A8%E5%85%A5/"><span class="level-start"><span class="level-item">sql注入</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"><span class="level-start"><span class="level-item">文件上传</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/php%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"><span class="tag">php代码审计</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python%E7%88%AC%E8%99%AB/"><span class="tag">python爬虫</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sql%E6%B3%A8%E5%85%A5/"><span class="tag">sql注入</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"><span class="tag">文件上传</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-30T12:42:14.000Z">2020-03-30</time></p><p class="title is-6"><a class="link-muted" href="/kali%E5%AE%89%E8%A3%85/">kali安装</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-28T01:58:28.000Z">2020-03-28</time></p><p class="title is-6"><a class="link-muted" href="/%E9%AA%8C%E8%AF%81%E7%A0%81%E5%AE%89%E5%85%A8/">验证码安全</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-25T11:07:25.000Z">2020-03-25</time></p><p class="title is-6"><a class="link-muted" href="/ctf/">ctf</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-25T10:10:07.000Z">2020-03-25</time></p><p class="title is-6"><a class="link-muted" href="/xxe%E6%BC%8F%E6%B4%9E/">xxe漏洞</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-25T10:09:15.000Z">2020-03-25</time></p><p class="title is-6"><a class="link-muted" href="/%E9%80%BB%E8%BE%91%E6%BC%8F%E6%B4%9E/">逻辑漏洞</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/02/"><span class="level-start"><span class="level-item">二月 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="WebDog" height="28"></a><p class="size-small"><span>&copy; 2020 WebDog</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>