<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>python爬虫实践 - WebDog</title><meta description="1.中国大学排名(定向爬取) 爬取路线：requests+bs4； 定向爬虫：仅对某一特定的页面进行爬取，不扩展爬取； 可行性： http:&amp;#x2F;&amp;#x2F;www.zuihaodaxue.com&amp;#x2F;robots.txt； 实现结果： 页面结构： 12345678910111213141516171819&amp;lt;tbody class&amp;#x3D;&amp;quot;hidden_zhpm&amp;quot; style&amp;#x3D;&amp;quot;text-align: center"><meta property="og:type" content="blog"><meta property="og:title" content="python爬虫实践"><meta property="og:url" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/"><meta property="og:site_name" content="WebDog"><meta property="og:description" content="1.中国大学排名(定向爬取) 爬取路线：requests+bs4； 定向爬虫：仅对某一特定的页面进行爬取，不扩展爬取； 可行性： http:&amp;#x2F;&amp;#x2F;www.zuihaodaxue.com&amp;#x2F;robots.txt； 实现结果： 页面结构： 12345678910111213141516171819&amp;lt;tbody class&amp;#x3D;&amp;quot;hidden_zhpm&amp;quot; style&amp;#x3D;&amp;quot;text-align: center"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/1.png"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/2.png"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.jpg"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/4.png"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/5.png"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/6.png"><meta property="og:image" content="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.png"><meta property="article:published_time" content="2020-02-11T13:19:02.000Z"><meta property="article:modified_time" content="2020-04-11T09:18:17.008Z"><meta property="article:author" content="WebDog"><meta property="article:tag" content="python爬虫"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/"},"headline":"WebDog","image":["http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/1.png","http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/2.png","http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.jpg","http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/4.png","http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/5.png","http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/6.png","http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.png"],"datePublished":"2020-02-11T13:19:02.000Z","dateModified":"2020-04-11T09:18:17.008Z","author":{"@type":"Person","name":"WebDog"},"description":"1.中国大学排名(定向爬取) 爬取路线：requests+bs4； 定向爬虫：仅对某一特定的页面进行爬取，不扩展爬取； 可行性： http:&#x2F;&#x2F;www.zuihaodaxue.com&#x2F;robots.txt； 实现结果： 页面结构： 12345678910111213141516171819&lt;tbody class&#x3D;&quot;hidden_zhpm&quot; style&#x3D;&quot;text-align: center"}</script><link rel="canonical" href="http://yoursite.com/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/"><link rel="alternative" href="/atom.xml" title="WebDog" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="WebDog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/webysx"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-02-11T13:19:02.000Z" title="2020-02-11T13:19:02.000Z">2020-02-11</time><span class="level-item"><a class="link-muted" href="/categories/python%E7%88%AC%E8%99%AB/">python爬虫</a></span><span class="level-item">12 分钟 读完 (大约 1857 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">python爬虫实践</h1><div class="content"><h1 id="1-中国大学排名-定向爬取"><a href="#1-中国大学排名-定向爬取" class="headerlink" title="1.中国大学排名(定向爬取)"></a>1.中国大学排名(定向爬取)</h1><p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/1.png" alt="1"></p>
<p><strong>爬取路线：</strong>requests+bs4；</p>
<p><strong>定向爬虫：</strong>仅对某一特定的页面进行爬取，不扩展爬取；</p>
<p><strong>可行性：</strong> <a href="http://www.zuihaodaxue.com/robots.txt；">http://www.zuihaodaxue.com/robots.txt；</a></p>
<p><strong>实现结果：</strong></p>
<p><strong>页面结构：</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;tbody class="hidden_zhpm" style="text-align: center;"&gt;</span><br><span class="line">	&lt;tr class="alt"&gt;</span><br><span class="line">		&lt;td&gt;1&lt;/td&gt;</span><br><span class="line">		&lt;td&gt;	</span><br><span class="line">			&lt;div align="left"&gt;清华大学&lt;/div&gt;</span><br><span class="line">		&lt;/td&gt;</span><br><span class="line">		&lt;td&gt;北京&lt;/td&gt;</span><br><span class="line">		&lt;td&gt;95.3&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator5"&gt;100.0&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator6" style="display: none;"&gt;97.50%&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator7" style="display: none;"&gt;1182145&lt;/td&gt;</span><br><span class="line">            &lt;td class="hidden-xs need-hidden indicator8" style="display: none;"&gt;44730&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator9" style="display: none;"&gt;1.447&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator10" style="display: none;"&gt;1556&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator11" style="display: none;"&gt;121&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator12" style="display: none;"&gt;1586283&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator13" style="display: none;"&gt;500525&lt;/td&gt;</span><br><span class="line">		&lt;td class="hidden-xs need-hidden indicator14" style="display: none;"&gt;6.90%&lt;/td&gt;</span><br><span class="line">	&lt;/tr&gt;</span><br></pre></td></tr></table></figure>

<p><strong>思路：</strong></p>
<ol>
<li>从网页上获取页面内容;</li>
<li>提取需要的数据；</li>
<li>输出结果。</li>
</ol>
<p><strong>代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取页面内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,timeout = <span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提取关键信息,将html页面存放在ulist列表中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">university_list</span><span class="params">(ulist,text)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(text,<span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>,class_ = <span class="string">"hidden_zhpm"</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr,bs4.element.Tag):<span class="comment">#isinstance函数检查tr中的内容是否是标签类型，过滤字符串类型</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>)</span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string,tds[<span class="number">1</span>].string,tds[<span class="number">2</span>].string,tds[<span class="number">3</span>].string,tds[<span class="number">4</span>].string])</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出结果,num表示打印的学校数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_university_list</span><span class="params">(ulist,num)</span>:</span></span><br><span class="line">    list_width=<span class="string">"&#123;0:&#123;5&#125;^6&#125;\t&#123;1:&#123;5&#125;^10&#125;\t&#123;2:&#123;5&#125;^6&#125;\t&#123;3:&#123;5&#125;^6&#125;\t&#123;4:&#123;5&#125;^6&#125;"</span></span><br><span class="line">    <span class="comment">#&#123;5&#125;表示采用chr(12288)格式进行填充</span></span><br><span class="line">    print(list_width.format(<span class="string">"排名"</span>,<span class="string">"学校名称"</span>,<span class="string">"省市"</span>,<span class="string">"总分"</span>,<span class="string">"生源质量"</span>,chr(<span class="number">12288</span>)))<span class="comment">#打印表头</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):<span class="comment">#利用循环打印列表</span></span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(list_width.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>],u[<span class="number">3</span>],u[<span class="number">4</span>],chr(<span class="number">12288</span>)))</span><br><span class="line">        </span><br><span class="line">university_info=[]</span><br><span class="line">url = <span class="string">'http://www.zuihaodaxue.com/zuihaodaxuepaiming2018.html'</span></span><br><span class="line">html = getHTMLText(url)</span><br><span class="line">university_list(university_info,html)</span><br><span class="line">input_university_list(university_info,<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/2.png" alt="1"></p>
<p><strong>format说明：</strong></p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.jpg" alt="3"></p>
<p>format方法最主要的两个属性是填充和宽度。当从网页上爬取的文本的宽度大于或小于format设定的宽度时，format就会自动按其内定的格式进行填补，默认情况下采用英文的空格。但如果在处理汉字的时候就会遇到问题，因为汉字和英文空格的宽度不同，所以会遇到不对齐的情况。这里的解决方法就是使用<code>chr(12288)</code>的格式来进行填充。</p>
<h1 id="2-爬取静态网站图片（re）"><a href="#2-爬取静态网站图片（re）" class="headerlink" title="2.爬取静态网站图片（re）"></a>2.爬取静态网站图片（re）</h1><p>request + re + time + os </p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import time</span><br><span class="line">import os</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">'''</span><br><span class="line">获取页面</span><br><span class="line">'''</span><br><span class="line">header = &#123;<span class="emphasis">'user-agent'</span>:</span><br><span class="line"><span class="code"> 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'&#125;</span></span><br><span class="line">url = "https://www.nange.cn/gallery/dreams"</span><br><span class="line">r = requests.get(url, headers = header)</span><br><span class="line">html = r.text</span><br><span class="line"></span><br><span class="line">'''</span><br><span class="line">解析页面</span><br><span class="line">'''</span><br><span class="line">urls = re.findall(<span class="emphasis">'&lt;a class=".*?" href="(.*?)" target=".*?" &gt;&lt;/a&gt;'</span>, html)</span><br><span class="line">dir<span class="emphasis">_name = re.findall('&lt;h1&gt;(.*?)&lt;/h1&gt;', html)[-1]</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">'''</span></span><br><span class="line"><span class="emphasis">创建目录，下载照片</span></span><br><span class="line"><span class="emphasis">'''</span></span><br><span class="line"><span class="emphasis">if not os.path.exists(dir_</span>name):</span><br><span class="line"><span class="code">    os.mkdir(dir_name)</span></span><br><span class="line"></span><br><span class="line">for url in urls:</span><br><span class="line"><span class="code">    time.sleep(1)</span></span><br><span class="line"><span class="code">    response = requests.get(url, headers = header)</span></span><br><span class="line"><span class="code">    file_name = url.split('/')[-1]</span></span><br><span class="line"><span class="code">    with open(dir_name + '\\' + file_name, 'wb') as f:</span></span><br><span class="line"><span class="code">        f.write(response.content)</span></span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/4.png" alt="4"></p>
<h1 id="3-爬取静态网站图片（Xpath）"><a href="#3-爬取静态网站图片（Xpath）" class="headerlink" title="3.爬取静态网站图片（Xpath）"></a>3.爬取静态网站图片（Xpath）</h1><p>request + parsel（Xpath） + time + os </p>
<figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> parsel</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"></span><br><span class="line">header = &#123;<span class="string">'user-agent'</span>:</span><br><span class="line"> <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">"https://blog.ccswust.org/14569.html"</span></span><br><span class="line">r = requests.get(url, headers = header)</span><br><span class="line">html = r.<span class="keyword">text</span></span><br><span class="line"><span class="keyword">data</span> = parsel.Selector(html)</span><br><span class="line"></span><br><span class="line">dir_name = <span class="string">'./爬虫代码/3'</span> + <span class="string">'/'</span> + <span class="keyword">data</span>.xpath(<span class="string">'//h1[@class="article-title"]/text()'</span>).extract()[-<span class="number">1</span>]</span><br><span class="line">urls = <span class="keyword">data</span>.xpath(<span class="string">'//p/img/@src'</span>).extract()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">not</span> os.<span class="built_in">path</span>.exists(dir_name):</span><br><span class="line">    os.mkdir(dir_name)</span><br><span class="line"><span class="keyword">for</span> url <span class="built_in">in</span> urls:</span><br><span class="line">    <span class="built_in">time</span>.sleep(<span class="number">1</span>)</span><br><span class="line">    r = requests.get(url, headers = header)</span><br><span class="line">    file_name = url.split(<span class="string">'?'</span>)[<span class="number">0</span>].split(<span class="string">'/'</span>)</span><br><span class="line">    file_name = file_name[-<span class="number">3</span>] + file_name[-<span class="number">2</span>] + file_name[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">with</span> open(dir_name + <span class="string">'/'</span> + file_name, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/5.png" alt="5"></p>
<h1 id="3-猫眼电影Top100（mongo数据库）"><a href="#3-猫眼电影Top100（mongo数据库）" class="headerlink" title="3.猫眼电影Top100（mongo数据库）"></a>3.猫眼电影Top100（mongo数据库）</h1><p>requests + xpath + mongo数据库</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import parsel</span><br><span class="line">import pymongo</span><br><span class="line">import time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Maoyan</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, url, headers)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.url = url</span><br><span class="line">        <span class="keyword">self</span>.headers = headers</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 请求页面</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_html</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        r = requests.get(<span class="keyword">self</span>.url, headers=<span class="keyword">self</span>.headers)</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">self</span>.html = r.text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析页面（Xpath）,返回字典</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        data = parsel.Selector(<span class="keyword">self</span>.html)</span><br><span class="line">        <span class="keyword">self</span>.names = data.xpath(<span class="string">'//p[@class="name"]/a/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">self</span>.stars = data.xpath(<span class="string">'//p[@class="star"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">self</span>.releasetimes = data.xpath(<span class="string">'//p[@class="releasetime"]/text()'</span>).extract()</span><br><span class="line">        score1 = data.xpath(<span class="string">'//p[@class="score"]/i[@class="integer"]/text()'</span>).extract()</span><br><span class="line">        score2 = data.xpath(<span class="string">'//p[@class="score"]/i[@class="fraction"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">self</span>.scores = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.scores.append(score1[i] + score2[i])</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.9'</span>,</span><br><span class="line">    <span class="string">'Cache-Control'</span>: <span class="string">'max-age=0'</span>,</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">    <span class="string">'Cookie'</span>: <span class="string">'_lxsdk_s=1714d9e4259-ff7-dcf-a5e%7C%7C1'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'maoyan.com'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-Dest'</span>: <span class="string">'document'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-Mode'</span>: <span class="string">'navigate'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-Site'</span>: <span class="string">'cross-site'</span>,</span><br><span class="line">    <span class="string">'Sec-Fetch-User'</span>: <span class="string">'?1'</span>,</span><br><span class="line">    <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mongo_connect = <span class="string">'mongodb://localhost:27017'</span> <span class="comment">#数据库连接</span></span><br><span class="line">mongo_db_name = <span class="string">'maoying_movies'</span> <span class="comment">#数据库名</span></span><br><span class="line">mongo_collection_name = <span class="string">'movies'</span> <span class="comment">#表名</span></span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(mongo_connect) <span class="comment">#创建连接（继承MongoClient类）</span></span><br><span class="line">db = client[mongo_db_name] <span class="comment">#创建数据库</span></span><br><span class="line">collection = db[mongo_collection_name] <span class="comment">#创建表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取top100</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    url = <span class="string">"https://maoyan.com/board/4?offset="</span> + str(i * <span class="number">10</span>) <span class="comment">#翻页规则</span></span><br><span class="line">    data = Maoyan(url, headers)</span><br><span class="line">    data.get_html()</span><br><span class="line">    data.get_data()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">        print(data.names[i].strip() + data.stars[i].strip() + data.releasetimes[i].strip() + data.scores[i].strip())</span><br><span class="line">	<span class="comment">#存入数据库</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">        movie = &#123;</span><br><span class="line">            <span class="string">'name'</span>: data.names[i].strip(),</span><br><span class="line">            <span class="string">'start'</span>: data.stars[i].strip(),</span><br><span class="line">            <span class="string">'releasetime'</span>: data.releasetimes[i].strip(),</span><br><span class="line">            <span class="string">'score'</span>: data.scores[i].strip()</span><br><span class="line">        &#125;</span><br><span class="line">        collection.update_one(&#123;<span class="string">'name'</span>: movie[<span class="string">'name'</span>]&#125;, &#123;<span class="string">'$set'</span>: movie&#125;, upsert=True)</span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        使用update_one来更新或插入数据，第一个&#123;&#125;表示查询条件，第二个&#123;&#125;利用$set操作符插入数据，upsert表示更新或插入，那么存在则更新，不存在则插入（创建）</span></span><br><span class="line"><span class="string">'</span><span class="string">''</span></span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/6.png" alt="6"></p>
<h1 id="4-拉勾网"><a href="#4-拉勾网" class="headerlink" title="4.拉勾网"></a>4.拉勾网</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"><span class="comment">#import pprint</span></span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取要访问页面的cookie</span></span><br><span class="line">def get_cookies(url):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">        &#125;</span><br><span class="line">    response = requests.<span class="builtin-name">get</span>(url, headers = headers)</span><br><span class="line">    return response.cookies</span><br><span class="line"></span><br><span class="line"><span class="comment">#要访问的页面所需要的表单数据（在浏览器中找），除第一页外，其他页都有sid参数，sid参数从前一个页面获取</span></span><br><span class="line">def get_data(first, pn, sid):</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'first'</span>: first,</span><br><span class="line">        <span class="string">'pn'</span>: pn,</span><br><span class="line">        <span class="string">'kd'</span>: <span class="string">'python'</span>,</span><br><span class="line">        <span class="string">'sid'</span>: sid</span><br><span class="line">    &#125;</span><br><span class="line">    return data</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Origin'</span>: <span class="string">'https://www.lagou.com'</span>,</span><br><span class="line">    <span class="string">'Referer'</span>: <span class="string">'https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput='</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span><span class="built_in"> page </span><span class="keyword">in</span> range(1,31):</span><br><span class="line">    time.sleep(11)</span><br><span class="line">    <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">    经过分析，访问https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput=无法获取数据，</span></span><br><span class="line"><span class="string">    需要在xhr中找到对应的数据页面然后通过规定的方法（post）发送请求，其中cookie可在链接过来的页面的到（referer）</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    url = <span class="string">"https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false"</span></span><br><span class="line">    cookies = get_cookies(<span class="string">'https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput='</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span><span class="built_in"> page </span>== 1:</span><br><span class="line">        first = <span class="literal">True</span></span><br><span class="line">        sid = <span class="string">''</span></span><br><span class="line">        data = get_data(first, page, sid)    </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        first = <span class="literal">False</span></span><br><span class="line">        data = get_data(first, page, sid)</span><br><span class="line">    </span><br><span class="line">    response = requests.post(url, headers = headers, <span class="attribute">data</span>=data, cookies = cookies)</span><br><span class="line">    data_response = response.json()</span><br><span class="line">    sid = data_response[<span class="string">'content'</span>][<span class="string">'showId'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">    信息提取</span></span><br><span class="line"><span class="string">    '</span>city<span class="string">': 城市</span></span><br><span class="line"><span class="string">    '</span>companyFullName<span class="string">': 公司名</span></span><br><span class="line"><span class="string">    '</span>companySize<span class="string">': 公司规模</span></span><br><span class="line"><span class="string">    '</span>education<span class="string">': 学历</span></span><br><span class="line"><span class="string">    '</span>positionName<span class="string">': 职位名称</span></span><br><span class="line"><span class="string">    '</span>salary<span class="string">': 薪资</span></span><br><span class="line"><span class="string">    '</span>workYear<span class="string">': 工作时间</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    results = data_response[<span class="string">'content'</span>][<span class="string">'positionResult'</span>][<span class="string">'result'</span>]</span><br><span class="line">    with open(<span class="string">'拉勾职位信息.csv'</span>, <span class="attribute">mode</span>=<span class="string">'a'</span>, <span class="attribute">encoding</span>=<span class="string">'utf-8'</span>) as f:</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> results:</span><br><span class="line">            d = &#123;</span><br><span class="line">                <span class="string">'city'</span> : r[<span class="string">'city'</span>],</span><br><span class="line">                <span class="string">'companyFullName'</span> : r[<span class="string">'companyFullName'</span>],</span><br><span class="line">                <span class="string">'companySize'</span> : r[<span class="string">'companySize'</span>],</span><br><span class="line">                <span class="string">'education'</span> : r[<span class="string">'education'</span>],</span><br><span class="line">                <span class="string">'positionName'</span> : r[<span class="string">'positionName'</span>],</span><br><span class="line">                <span class="string">'salary'</span> : r[<span class="string">'salary'</span>],</span><br><span class="line">                <span class="string">'workYear'</span> : r[<span class="string">'workYear'</span>]</span><br><span class="line">            &#125;</span><br><span class="line">            values = d.values()</span><br><span class="line">            f.write(<span class="string">","</span>.join(values))</span><br><span class="line">            f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="/python%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5/3.png" alt="5"></p>
<h1 id="5-爬取快代理构建ip池"><a href="#5-爬取快代理构建ip池" class="headerlink" title="5.爬取快代理构建ip池"></a>5.爬取快代理构建ip池</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import parsel</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def check_proxy(proxy_list):</span><br><span class="line">    # 检查ip质量</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    can_use = []</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> proxy </span><span class="keyword">in</span> proxy_list:</span><br><span class="line">        try:</span><br><span class="line">            response = requests.<span class="builtin-name">get</span>(<span class="string">'https://www.baidu.com/'</span>, headers = headers, proxies = proxy, timeout = 0.1)</span><br><span class="line">            <span class="keyword">if</span> response.status_code == 200:</span><br><span class="line">                can_use.append(proxy)</span><br><span class="line">        except Exception as e:</span><br><span class="line">            <span class="builtin-name">print</span>(e)</span><br><span class="line">    return can_use</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line">proxy_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span><span class="built_in"> page </span><span class="keyword">in</span> range(1,11):</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">"====================正在爬取第&#123;&#125;页==================="</span>.format(page))</span><br><span class="line"></span><br><span class="line">    url = <span class="string">'https://www.kuaidaili.com/free/inha/&#123;&#125;/'</span>.format(page)</span><br><span class="line">    r = requests.<span class="builtin-name">get</span>(url, headers = headers)</span><br><span class="line">    # ip，端口，协议类型</span><br><span class="line">    data = parsel.Selector(r.text)</span><br><span class="line">    proxies = data.xpath(<span class="string">'//table[@class="table table-bordered table-striped"]/tbody/tr'</span>)</span><br><span class="line"></span><br><span class="line">    # 代理ip的形式：&#123;<span class="string">'协议类型'</span>：<span class="string">'ip: 端口'</span>&#125;</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> proxy </span><span class="keyword">in</span> proxies:</span><br><span class="line">        proxy_dict = &#123;&#125;</span><br><span class="line">       <span class="built_in"> ip </span>= proxy.xpath(<span class="string">'./td[@data-title="IP"]/text()'</span>).extract()</span><br><span class="line">       <span class="built_in"> port </span>= proxy.xpath(<span class="string">'./td[@data-title="PORT"]/text()'</span>).extract()</span><br><span class="line">        pro_style = proxy.xpath(<span class="string">'./td[@data-title="类型"]/text()'</span>).extract()</span><br><span class="line">        proxy_dict[<span class="string">'pro_style'</span>] = str(ip) + <span class="string">': '</span> + str(port)</span><br><span class="line">        proxy_list.append(proxy_dict)</span><br><span class="line">        <span class="builtin-name">print</span>(proxy_dict)</span><br><span class="line"></span><br><span class="line">    time.sleep(1)</span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">"===================第&#123;&#125;页爬取结束====================="</span>.format(page))</span><br><span class="line"></span><br><span class="line">can_use = check_proxy(proxy_list)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'能用的代理ip：'</span>, can_use)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'能用的代理ip数量：'</span>, len(can_use))</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/python%E7%88%AC%E8%99%AB/">python爬虫</a></div><div class="sharethis-inline-share-buttons"></div><script src="/" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/zhifubao.jpg" alt="支付宝"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/weixin.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Scrapy%E6%A1%86%E6%9E%B6/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Scrapy框架</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/"><span class="level-item">python爬虫基础</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="" src="/img/avatar.png" alt="WebDog"></figure><p class="title is-size-4 is-block line-height-inherit">WebDog</p><p class="is-size-6 is-block">莫得感情的Web渗透测试机器</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ChengDu</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/webysx" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/webysx"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/php%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"><span class="level-start"><span class="level-item">php代码审计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/python%E7%88%AC%E8%99%AB/"><span class="level-start"><span class="level-item">python爬虫</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/sql%E6%B3%A8%E5%85%A5/"><span class="level-start"><span class="level-item">sql注入</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"><span class="level-start"><span class="level-item">文件上传</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/php%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"><span class="tag">php代码审计</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python%E7%88%AC%E8%99%AB/"><span class="tag">python爬虫</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sql%E6%B3%A8%E5%85%A5/"><span class="tag">sql注入</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"><span class="tag">文件上传</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-30T12:42:14.000Z">2020-03-30</time></p><p class="title is-6"><a class="link-muted" href="/kali%E5%AE%89%E8%A3%85/">kali安装</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-28T01:58:28.000Z">2020-03-28</time></p><p class="title is-6"><a class="link-muted" href="/%E9%AA%8C%E8%AF%81%E7%A0%81%E5%AE%89%E5%85%A8/">验证码安全</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-25T11:07:25.000Z">2020-03-25</time></p><p class="title is-6"><a class="link-muted" href="/ctf/">ctf</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-25T10:10:07.000Z">2020-03-25</time></p><p class="title is-6"><a class="link-muted" href="/xxe%E6%BC%8F%E6%B4%9E/">xxe漏洞</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-25T10:09:15.000Z">2020-03-25</time></p><p class="title is-6"><a class="link-muted" href="/%E9%80%BB%E8%BE%91%E6%BC%8F%E6%B4%9E/">逻辑漏洞</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/02/"><span class="level-start"><span class="level-item">二月 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="WebDog" height="28"></a><p class="size-small"><span>&copy; 2020 WebDog</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>